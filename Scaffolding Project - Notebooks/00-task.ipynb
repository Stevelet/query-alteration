{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaffolding project\n",
    "\n",
    "Welcome to the __IN4325: Information Retrieval__ lecture!\n",
    "\n",
    "This project acts as a gentle introduction to information retrieval for you. You do not need any prior knowledge about IR for this task. Only some Python programming skills are required.\n",
    "\n",
    "## Getting started\n",
    "Under the hood, this notebook uses a library called __PyTerrier__. Please check out the first part of our _Introduction to PyTerrier_ series to learn how to install PyTerrier. However, you do not need to interact with PyTerrier directly for now; rather, we're providing you with simple utility functions you can use. Feel free to have a look how these are implemented, but it's not required.\n",
    "\n",
    "__Task 1__: Install PyTerrier (see the `01-setup.ipynb` notebook).\n",
    "\n",
    "Now you should be able to import the utility functions. The first time you do this, a dataset will be downloaded and indexed automatically (this will take a minute). If you have any issues running this cell, try removing the `index` directory (if it exists) and restarting the kernel of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from util import search, evaluate, evaluate_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the data, you can run search queries. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>252644</td>\n",
       "      <td>3702072_14</td>\n",
       "      <td>there is no meaning to life, it is only the af...</td>\n",
       "      <td>0</td>\n",
       "      <td>15.566330</td>\n",
       "      <td>what is the meaning of life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>217423</td>\n",
       "      <td>1761229_12</td>\n",
       "      <td>the meaning of life is to search for the meani...</td>\n",
       "      <td>1</td>\n",
       "      <td>15.334672</td>\n",
       "      <td>what is the meaning of life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>169345</td>\n",
       "      <td>3619417_9</td>\n",
       "      <td>The meaning of life is simple: \"There is life ...</td>\n",
       "      <td>2</td>\n",
       "      <td>15.015069</td>\n",
       "      <td>what is the meaning of life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>91240</td>\n",
       "      <td>1142437_3</td>\n",
       "      <td>Life doesn't require meaning.  Life need have ...</td>\n",
       "      <td>3</td>\n",
       "      <td>14.797602</td>\n",
       "      <td>what is the meaning of life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>203572</td>\n",
       "      <td>3958274_0</td>\n",
       "      <td>no meaning.. what else have meaning?. if meani...</td>\n",
       "      <td>4</td>\n",
       "      <td>14.732545</td>\n",
       "      <td>what is the meaning of life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>121641</td>\n",
       "      <td>239942_7</td>\n",
       "      <td>Life only takes on the meaning that we give it...</td>\n",
       "      <td>5</td>\n",
       "      <td>14.730245</td>\n",
       "      <td>what is the meaning of life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>102700</td>\n",
       "      <td>783019_0</td>\n",
       "      <td>Biology is the study of life. Bio means life a...</td>\n",
       "      <td>6</td>\n",
       "      <td>14.471157</td>\n",
       "      <td>what is the meaning of life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>398376</td>\n",
       "      <td>1630688_0</td>\n",
       "      <td>Donia means : life on earth... . hayat means l...</td>\n",
       "      <td>7</td>\n",
       "      <td>14.407119</td>\n",
       "      <td>what is the meaning of life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>183988</td>\n",
       "      <td>2056871_14</td>\n",
       "      <td>to find out why people constantly ask this que...</td>\n",
       "      <td>8</td>\n",
       "      <td>14.205518</td>\n",
       "      <td>what is the meaning of life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>169340</td>\n",
       "      <td>3619417_4</td>\n",
       "      <td>life mean to do some thing for other</td>\n",
       "      <td>9</td>\n",
       "      <td>14.161821</td>\n",
       "      <td>what is the meaning of life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid   docid       docno                                               text  \\\n",
       "0   1  252644  3702072_14  there is no meaning to life, it is only the af...   \n",
       "1   1  217423  1761229_12  the meaning of life is to search for the meani...   \n",
       "2   1  169345   3619417_9  The meaning of life is simple: \"There is life ...   \n",
       "3   1   91240   1142437_3  Life doesn't require meaning.  Life need have ...   \n",
       "4   1  203572   3958274_0  no meaning.. what else have meaning?. if meani...   \n",
       "5   1  121641    239942_7  Life only takes on the meaning that we give it...   \n",
       "6   1  102700    783019_0  Biology is the study of life. Bio means life a...   \n",
       "7   1  398376   1630688_0  Donia means : life on earth... . hayat means l...   \n",
       "8   1  183988  2056871_14  to find out why people constantly ask this que...   \n",
       "9   1  169340   3619417_4               life mean to do some thing for other   \n",
       "\n",
       "   rank      score                        query  \n",
       "0     0  15.566330  what is the meaning of life  \n",
       "1     1  15.334672  what is the meaning of life  \n",
       "2     2  15.015069  what is the meaning of life  \n",
       "3     3  14.797602  what is the meaning of life  \n",
       "4     4  14.732545  what is the meaning of life  \n",
       "5     5  14.730245  what is the meaning of life  \n",
       "6     6  14.471157  what is the meaning of life  \n",
       "7     7  14.407119  what is the meaning of life  \n",
       "8     8  14.205518  what is the meaning of life  \n",
       "9     9  14.161821  what is the meaning of life  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"what is the meaning of life\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you get here is a list of ten documents from the corpus that are ordered by how relevant they are to our query (according to the search engine).\n",
    "\n",
    "## Query rewriting\n",
    "The goal of this task is to come up with a way of __rewriting queries__ such that the search engine can \"understand\" them better.\n",
    "\n",
    "In order to do this, let's first take a look at some example queries from our dataset. We represent these queries using a `pandas.DataFrame`, where the first column corresponds to the __query ID__ and the second column corresponds to the __query__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "example_queries = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            \"443848\",\n",
    "            \"does anybody know where i could get a free guide on how to train a siberian husky\",\n",
    "        ],\n",
    "        [\n",
    "            \"1783010\",\n",
    "            \"what is blaphsemy\",\n",
    "        ],\n",
    "        [\n",
    "            \"2838988\",\n",
    "            \"how can i get a cork out of not into a wine bottle without a corkscrew\",\n",
    "        ],\n",
    "    ],\n",
    "    columns=[\"qid\", \"query\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these queries are taken from the dataset, we can __evaluate the performance__ of our search engine on these queries. This means that we know which documents the system should retrieve for each query.\n",
    "\n",
    "You can use the following evaluation function to do this. This function takes your queries and returns a score (mean average precision -- you will learn about this later). For now, all you need to know is that, the higher this score, the better the system works.\n",
    "\n",
    "Let's evaluate the queries we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.5223984383435115\n"
     ]
    }
   ],
   "source": [
    "print(\"score:\", evaluate(example_queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's up to you to figure out if and how it's possible to make the search engine perform better on these queries. How would you query a search engine if you wanted to know about these topics? Experiment a bit.\n",
    "\n",
    "__Task 2__: Try to manually come up with ways to rewrite or reformulate the queries so the performance improves.\n",
    "\n",
    "__Important__: Make sure that the query IDs match! Otherwise, evaluation will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score after rewriting: 0.538588696112892\n"
     ]
    }
   ],
   "source": [
    "example_queries_rewritten = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            \"443848\",\n",
    "            \"free guide on how to train siberian husky\", # TODO: add rewritten query here\n",
    "        ],\n",
    "        [\n",
    "            \"1783010\",\n",
    "            \"blasphemy what\", # TODO: add rewritten query here\n",
    "        ],\n",
    "        [\n",
    "            \"2838988\",\n",
    "            \"how can i get a cork out of wine bottle without corkscrew\", # TODO: add rewritten query here\n",
    "        ],\n",
    "    ],\n",
    "    columns=[\"qid\", \"query\"],\n",
    ")\n",
    "print(\"score after rewriting:\", evaluate(example_queries_rewritten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An automatic approach\n",
    "\n",
    "In this last part, we'll try to come up with an automatic approach to perform query re-writing. Use your findings from task 2 for this.\n",
    "\n",
    "__Task 3__: Implement a function that automatically re-writes any input query.\n",
    "\n",
    "You can use any approach or library you want for this task. However, keep in mind that simple ideas often work well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyenchant in /home/steve/.local/lib/python3.8/site-packages (3.2.2)\n",
      "Requirement already satisfied: autocorrect in /home/steve/.local/lib/python3.8/site-packages (2.6.1)\n",
      "Requirement already satisfied: nltk in /home/steve/.local/lib/python3.8/site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/steve/.local/lib/python3.8/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /home/steve/.local/lib/python3.8/site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: joblib in /home/steve/.local/lib/python3.8/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (7.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/steve/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell for importing python packages to the current kernel\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install pyenchant\n",
    "!{sys.executable} -m pip install autocorrect\n",
    "!{sys.executable} -m pip install nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes from lecure about queries.\n",
    "\n",
    "- Average query length is 30 on specific websites, 2.8 for more general searches\n",
    "    - Maybe make query length depend on specificity of words in the initial query\n",
    "- Find similar earlier queries\n",
    "- Noisy channel probabalistic model for spell checking\n",
    "- Context improvement:\n",
    "    - Use wordnet to find context (siberian husky vs nigerian husky for example)\n",
    "    - Word co-occurrence in corpus for same improvement (more naive)\n",
    "- Look if uppercase version of word is in system as acronym\n",
    "- Markov models (for autocomplete)\n",
    "- mAP as a grading metric\n",
    "- Seven vs Sven paper implementation:\n",
    "    - Output -> Fully Connected Layer -> Recurrent Layer -> Embeddings -> Words\n",
    "    -        -> Features\n",
    "- Look into multi-language searching\n",
    "- Learning Multiple Intent Representations for Search Queries (llm paper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes from lectures about ranking\n",
    "\n",
    "- Sample from documents that are retrieved when a query is executed to find words that can be used to expand said query.\n",
    "    - Only grab documents that contain all keywords.\n",
    "- Use bigram (sliding window of size 2) to find documents containing the same bigram\n",
    "    - Split bigrams back into unigrams if no bigram is found from the query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "import numpy as np\n",
    "import re\n",
    "from autocorrect import Speller\n",
    "from nltk.corpus import words\n",
    "\n",
    "data = pt.datasets.get_dataset(\"irds:antique/test/non-offensive\")\n",
    "corp_iter = data.get_corpus_iter(verbose=False)\n",
    "\n",
    "idf_map = {}\n",
    "doc_lens = []\n",
    "\n",
    "p = os.path.join(os.getcwd(), 'my_index')\n",
    "if not os.path.exists(p):\n",
    "    os.mkdir(p)\n",
    "\n",
    "def seperate_words(quer):\n",
    "    return [re.sub(r\"[!.,?']$\", \"\", word).lower() for word in quer.split(' ')] # Split words in document text\n",
    "        \n",
    "# Create reverse word index and word length index for spelling correction.\n",
    "for item in corp_iter:\n",
    "    text_words = seperate_words(item['text'])\n",
    "    doc_lens.append(len(text_words)) # Store document lengths for IDF calculation\n",
    "    \n",
    "    docno = item['docno']\n",
    "    \n",
    "    f_path = os.path.join(p, docno + '.json')\n",
    "    \n",
    "    if os.path.exists(f_path):\n",
    "        os.remove(f_path)\n",
    "    \n",
    "    doc_map = {}\n",
    "    \n",
    "    for word in text_words:\n",
    "        entr = idf_map.setdefault(word, {}) # Add word to mapping\n",
    "        entr.setdefault(docno, 0) # Update word occurrence\n",
    "        entr[docno] = entr[docno] + 1\n",
    "        doc_map.setdefault(word, 0)\n",
    "        doc_map[word] = doc_map[word] + 1\n",
    "        \n",
    "    with open(f_path, 'w') as f:\n",
    "        json.dump(doc_map, f)\n",
    "\n",
    "# Add idf score to entries\n",
    "for key in list(idf_map.keys()):\n",
    "    entr = idf_map[key]\n",
    "    docs_containing = len(entr.keys()) # Get the amount of documents containing the word\n",
    "    total_docs = len(doc_lens) # Get total documents\n",
    "    idf = np.log(1 + ((total_docs - docs_containing + 0.5) / (docs_containing + 0.5)))\n",
    "    idf_map[key] = (idf, entr)\n",
    "    \n",
    "spell = Speller()\n",
    "word_set = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'does anybody know where could get free guide on how train siberian husky'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_word(local_word):\n",
    "    return idf_map[local_word][0] if local_word in idf_map.keys() else 0\n",
    "\n",
    "def rewrite_query(query: str) -> str:\n",
    "    parts = [part for part in seperate_words(query)]\n",
    "    scored_parts = sorted([(score_word(word), index, word) for index, word in enumerate(parts)])\n",
    "    \n",
    "    total_score = sum([part[0] for part in scored_parts])\n",
    "    boundry = total_score * 0.1\n",
    "    \n",
    "    sub_split = []\n",
    "    for i, part in enumerate(scored_parts):\n",
    "        summation = sum([s[0] for s in scored_parts[0:(i+1)]])\n",
    "        if summation > boundry:\n",
    "            sub_split = scored_parts[max(0, (i-1)):len(scored_parts)]\n",
    "            break\n",
    "    \n",
    "    sub_split = [item[1] for item in sorted([(part[1], part[2]) for part in sub_split])]\n",
    "    \n",
    "    query_co_oc = {}\n",
    "    for word in sub_split:\n",
    "        if word not in idf_map.keys():\n",
    "            continue\n",
    "        for key in idf_map[word][1].keys():\n",
    "            query_co_oc.setdefault(key, 0)\n",
    "            query_co_oc[key] = query_co_oc[key] + 1\n",
    "    query_co_oc = list(sorted(list(query_co_oc.items()), key=lambda x: x[1], reverse=True))\n",
    "    top_k = query_co_oc[0:10]\n",
    "    \n",
    "    merged_doc_map = {}\n",
    "    for pair in top_k:\n",
    "        f_path = os.path.join(p, pair[0] + '.json')\n",
    "        with open(f_path, 'r') as f:\n",
    "            d = json.load(f)\n",
    "            for key in d.keys():\n",
    "                merged_doc_map.setdefault(key, [set(), 0])\n",
    "                merged_doc_map[key][0].add(pair[0])\n",
    "                merged_doc_map[key][1] = merged_doc_map[key][1] + d[key]\n",
    "    \n",
    "    sorted_co_oc = list(sorted(filter(lambda y: len(y[1][0]) > 5, merged_doc_map.items()), key=lambda x: x[1][1], reverse=False))\n",
    "    \n",
    "    select_count = 30 - len(sub_split)\n",
    "    selected = list(filter(lambda x: len(x) > 0, [re.sub(r\"['\\'!?.,]\", \"\", tu[0]) for tu in sorted_co_oc]))[0:select_count]\n",
    "    \n",
    "    query = \" \".join(sub_split)\n",
    "    addition = \" \".join(selected)\n",
    "    \n",
    "    return query\n",
    "\n",
    "rewrite_query(\"does anybody know where i could get a free guide on how to train a siberian husky\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we'll evalute on _all_ queries in the dataset. This will give us a more general result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.4570052947026987\n"
     ]
    }
   ],
   "source": [
    "print(\"score:\", evaluate_all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you able to improve the overall performance using your rewriting approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score after rewriting 0.45670174444542516\n"
     ]
    }
   ],
   "source": [
    "print(\"score after rewriting\", evaluate_all(rewrite_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
